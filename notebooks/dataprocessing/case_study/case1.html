<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Case Study 1 &mdash; Responsible AI Mitigations  documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/nbsphinx-code-cells.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Case Study 2" href="case2.html" />
    <link rel="prev" title="Simple Example" href="../module_tests/model_test.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            Responsible AI Mitigations
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../install_guide.html">Installation guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../integration_to_libs.html">How this library works with the Responsible AI Toolbox</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api.html">API reference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../gallery.html">Gallery</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../gallery.html#tutorials">Tutorials</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../../gallery.html#case-studies">Case Studies</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../../../gallery.html#using-the-dataprocessing-module">Using the DataProcessing Module</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../module_tests/model_test.html">Simple Example</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">Case Study 1</a></li>
<li class="toctree-l4"><a class="reference internal" href="case2.html">Case Study 2</a></li>
<li class="toctree-l4"><a class="reference internal" href="case3.html">Case Study 3</a></li>
<li class="toctree-l4"><a class="reference internal" href="case1_stat.html">Case Study 1 - Multiple Runs</a></li>
<li class="toctree-l4"><a class="reference internal" href="case2_stat.html">Case Study 2 - Multiple Runs</a></li>
<li class="toctree-l4"><a class="reference internal" href="case3_stat.html">Case Study 3 - Multiple Runs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../gallery.html#using-the-databalanceanalysis-module">Using the DataBalanceAnalysis Module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../gallery.html#using-the-cohort-module">Using the Cohort Module</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Modules</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../dataprocessing/intro.html">DataProcessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../databalanceanalysis/intro.html">DataBalanceAnalysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cohort/intro.html">Cohort</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utils/utils.html">Utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Responsible AI Mitigations</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../gallery.html">Gallery</a></li>
      <li class="breadcrumb-item active">Case Study 1</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com//microsoft/responsible-ai-toolbox-mitigations/blob/main/docs/notebooks/dataprocessing/case_study/case1.ipynb" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">uci_dataset</span> <span class="k">as</span> <span class="nn">database</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">import</span> <span class="nn">raimitigations.dataprocessing</span> <span class="k">as</span> <span class="nn">dp</span>
<span class="kn">from</span> <span class="nn">raimitigations.utils</span> <span class="kn">import</span> <span class="n">split_data</span><span class="p">,</span> <span class="n">train_model_plot_results</span>
</pre></div>
</div>
</div>
<section id="Case-Study-1">
<h1>Case Study 1<a class="headerlink" href="#Case-Study-1" title="Permalink to this heading"></a></h1>
<p>This notebook shows an example of how to use the <strong>dataprocessing</strong> library. Here, we show how to use this library to explore and transform a dataset with the goal to improve a model’s accuracy. Here, we will work with the breast cancer dataset. The dataset is automatically fetched by using the <strong>uci_dataset</strong> library.</p>
<section id="Fixing-a-seed">
<h2>Fixing a seed<a class="headerlink" href="#Fixing-a-seed" title="Permalink to this heading"></a></h2>
<p>To avoid randomness in the following experiments, we’ll fix the seeds to guarantee that the results obtained are the same each time we run this notebook. Feel free to comment the next cell or test different seeds to see how this affects the results.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="n">SEED</span> <span class="o">=</span> <span class="mi">45</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;torch._C.Generator at 0x7f25279f79f0&gt;
</pre></div></div>
</div>
</section>
<section id="1---Understanding-the-Data">
<h2>1 - Understanding the Data<a class="headerlink" href="#1---Understanding-the-Data" title="Permalink to this heading"></a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">database</span><span class="o">.</span><span class="n">load_breast_cancer</span><span class="p">()</span>
<span class="n">label_col</span> <span class="o">=</span> <span class="s2">&quot;Class&quot;</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Class</th>
      <th>age</th>
      <th>menopause</th>
      <th>tumor-size</th>
      <th>inv-nodes</th>
      <th>node-caps</th>
      <th>deg-malig</th>
      <th>breast</th>
      <th>breast-quad</th>
      <th>irradiat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>no-recurrence-events</td>
      <td>30-39</td>
      <td>premeno</td>
      <td>30-34</td>
      <td>0-2</td>
      <td>no</td>
      <td>3</td>
      <td>left</td>
      <td>left_low</td>
      <td>no</td>
    </tr>
    <tr>
      <th>1</th>
      <td>no-recurrence-events</td>
      <td>40-49</td>
      <td>premeno</td>
      <td>20-24</td>
      <td>0-2</td>
      <td>no</td>
      <td>2</td>
      <td>right</td>
      <td>right_up</td>
      <td>no</td>
    </tr>
    <tr>
      <th>2</th>
      <td>no-recurrence-events</td>
      <td>40-49</td>
      <td>premeno</td>
      <td>20-24</td>
      <td>0-2</td>
      <td>no</td>
      <td>2</td>
      <td>left</td>
      <td>left_low</td>
      <td>no</td>
    </tr>
    <tr>
      <th>3</th>
      <td>no-recurrence-events</td>
      <td>60-69</td>
      <td>ge40</td>
      <td>15-19</td>
      <td>0-2</td>
      <td>no</td>
      <td>2</td>
      <td>right</td>
      <td>left_up</td>
      <td>no</td>
    </tr>
    <tr>
      <th>4</th>
      <td>no-recurrence-events</td>
      <td>40-49</td>
      <td>premeno</td>
      <td>0-4</td>
      <td>0-2</td>
      <td>no</td>
      <td>2</td>
      <td>right</td>
      <td>right_low</td>
      <td>no</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>281</th>
      <td>recurrence-events</td>
      <td>30-39</td>
      <td>premeno</td>
      <td>30-34</td>
      <td>0-2</td>
      <td>no</td>
      <td>2</td>
      <td>left</td>
      <td>left_up</td>
      <td>no</td>
    </tr>
    <tr>
      <th>282</th>
      <td>recurrence-events</td>
      <td>30-39</td>
      <td>premeno</td>
      <td>20-24</td>
      <td>0-2</td>
      <td>no</td>
      <td>3</td>
      <td>left</td>
      <td>left_up</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>283</th>
      <td>recurrence-events</td>
      <td>60-69</td>
      <td>ge40</td>
      <td>20-24</td>
      <td>0-2</td>
      <td>no</td>
      <td>1</td>
      <td>right</td>
      <td>left_up</td>
      <td>no</td>
    </tr>
    <tr>
      <th>284</th>
      <td>recurrence-events</td>
      <td>40-49</td>
      <td>ge40</td>
      <td>30-34</td>
      <td>3-5</td>
      <td>no</td>
      <td>3</td>
      <td>left</td>
      <td>left_low</td>
      <td>no</td>
    </tr>
    <tr>
      <th>285</th>
      <td>recurrence-events</td>
      <td>50-59</td>
      <td>ge40</td>
      <td>30-34</td>
      <td>3-5</td>
      <td>no</td>
      <td>3</td>
      <td>left</td>
      <td>left_low</td>
      <td>no</td>
    </tr>
  </tbody>
</table>
<p>286 rows × 10 columns</p>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 286 entries, 0 to 285
Data columns (total 10 columns):
 #   Column       Non-Null Count  Dtype
---  ------       --------------  -----
 0   Class        286 non-null    object
 1   age          286 non-null    object
 2   menopause    286 non-null    object
 3   tumor-size   286 non-null    object
 4   inv-nodes    286 non-null    object
 5   node-caps    278 non-null    object
 6   deg-malig    286 non-null    int64
 7   breast       286 non-null    object
 8   breast-quad  285 non-null    object
 9   irradiat     286 non-null    object
dtypes: int64(1), object(9)
memory usage: 22.5+ KB
</pre></div></div>
</div>
<p>There are several categorical data in this dataset. Actually, only one feature is numeric, while the remaining columns are all categorical. Therefore, we should take a closer look at each column in order to determine which encoding method should be used to each one. From the summary of the dataset, presented two cells up, we notice that many of the categorical classes doesn’t present any order. For these, we should use One-Hot encoding. However, some of these columns present some order among
their categories. For example, the <strong>age</strong> column presents a hierarchical information. Let’s take a look a these ordered categorical data:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;age unique values = </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;age&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tumor-size unique values = </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;tumor-size&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;inv-nodes unique values = </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inv-nodes&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
age unique values = [&#39;30-39&#39; &#39;40-49&#39; &#39;60-69&#39; &#39;50-59&#39; &#39;70-79&#39; &#39;20-29&#39;]
tumor-size unique values = [&#39;30-34&#39; &#39;20-24&#39; &#39;15-19&#39; &#39;0-4&#39; &#39;25-29&#39; &#39;50-54&#39; &#39;10-14&#39; &#39;40-44&#39; &#39;35-39&#39;
 &#39;5-9&#39; &#39;45-49&#39;]
inv-nodes unique values = [&#39;0-2&#39; &#39;6-8&#39; &#39;9-11&#39; &#39;3-5&#39; &#39;15-17&#39; &#39;12-14&#39; &#39;24-26&#39;]
</pre></div></div>
</div>
<p>After a few cells, we will use this information when encoding our data.</p>
<p>Before modifying the dataset, let’s analyze the correlations within its columns. To do that, let’s use the <strong>CorrelatedFeatures</strong> class, which computes the correlation between numerical x numerical, categorical x numerical, and categorical x categorical data. Please refer to the notebook in <strong>notebooks/module_tests/feat_sel_corr_tutorial.ipynb</strong> for an in depth analysis of this class. In a nutshell: this class will compute the correlation between all pairs of variables (or we can look only to a
specific set of variables if needed) and remove one variable for each pair of correlated variables. This class uses a fit method to compute the correlations and a transform method to effectively remove the correlated variables. For now, we are only interested in analysing the correlations between the columns. We will save the results found by this class in the files specified by <em>json_summary</em>, <em>json_corr</em>, and <em>json_uncorr</em>, respectively.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cor_feat</span> <span class="o">=</span> <span class="n">dp</span><span class="o">.</span><span class="n">CorrelatedFeatures</span><span class="p">(</span>
                                    <span class="n">method_num_num</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;spearman&quot;</span><span class="p">,</span> <span class="s2">&quot;pearson&quot;</span><span class="p">,</span> <span class="s2">&quot;kendall&quot;</span><span class="p">],</span>                              <span class="c1"># Used for Numerical x Numerical correlations</span>
                                    <span class="n">num_corr_th</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>                                                                                                <span class="c1"># Used for Numerical x Numerical correlations</span>
                                    <span class="n">num_pvalue_th</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>                                                                                             <span class="c1"># Used for Numerical x Numerical correlations</span>
                                    <span class="n">method_num_cat</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>                                                                                 <span class="c1"># Used for Numerical x Categorical correlations</span>
                                    <span class="n">model_metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;f1&quot;</span><span class="p">,</span> <span class="s2">&quot;auc&quot;</span><span class="p">],</span>                                                                    <span class="c1"># Used for Numerical x Categorical correlations</span>
                                    <span class="n">metric_th</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>                                                                                                  <span class="c1"># Used for Numerical x Categorical correlations</span>
                                    <span class="n">cat_corr_th</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>                                                                                                <span class="c1"># Used for Categorical x Categorical correlations</span>
                                    <span class="n">cat_pvalue_th</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>                                                                                             <span class="c1"># Used for Categorical x Categorical correlations</span>
                                    <span class="n">json_summary</span><span class="o">=</span><span class="s2">&quot;./corr_json/c1_summary.json&quot;</span><span class="p">,</span>
                                    <span class="n">json_corr</span><span class="o">=</span><span class="s2">&quot;./corr_json/c1_corr.json&quot;</span><span class="p">,</span>
                                    <span class="n">json_uncorr</span><span class="o">=</span><span class="s2">&quot;./corr_json/c1_uncorr.json&quot;</span>
                            <span class="p">)</span>
<span class="n">cor_feat</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">label_col</span><span class="o">=</span><span class="n">label_col</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
No correlations detected. Nothing to be done here.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;raimitigations.dataprocessing.feat_selection.correlated_features.CorrelatedFeatures at 0x7f259488ba00&gt;
</pre></div></div>
</div>
<p>Remember to look through the JSON files generated in the previous cell.</p>
</section>
<section id="2---Basic-Pre-Processing">
<h2>2 - Basic Pre-Processing<a class="headerlink" href="#2---Basic-Pre-Processing" title="Permalink to this heading"></a></h2>
<section id="Encode-Categorical-Variables">
<h3>Encode Categorical Variables<a class="headerlink" href="#Encode-Categorical-Variables" title="Permalink to this heading"></a></h3>
<p>The next step is crucial for preparing our dataset so it can be used by a model. As previously mentioned, we will encode the data using two encoding methods: ordinal encoding for categorical columns with ordered categories, and one-hot encoding for unordered categorical data. The columns “age”, “tumor-size”, “inv-nodes”, and “Class” will all be encoded using ordinal encoding. For the “age”, “tumor-size”, and “inv-nodes” columns, we provide a list with the ordered categories, which shows the
encoder how it should order the encoding numbers (lower values will be associated to the initial categories, while higher encoding values will be associated to the final categories). After creating the encoder object from the <strong>EncoderOrdinal</strong> class, we call its fit method while passing the dataset <strong>df</strong> to it. We then call the transform method, which returns a new copy of the dataset with the categorical columns specified encoded using ordinal encoding. We then proceed to perform the one-hot
encoding by instantiating an object of class <strong>EncoderOHE</strong> and then calling its fit and transform methods.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the order that the ordinal encoder should use</span>
<span class="n">age_order</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;age&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="n">age_order</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
<span class="n">tumor_size_order</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;tumor-size&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="n">tumor_size_order</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
<span class="n">inv_nodes_order</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;inv-nodes&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="n">inv_nodes_order</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>

<span class="c1"># Encode &#39;tumor-size&#39;, &#39;Class&#39;, and &#39;inv-nodes&#39; using ordinal encoding</span>
<span class="n">enc_ord</span> <span class="o">=</span> <span class="n">dp</span><span class="o">.</span><span class="n">EncoderOrdinal</span><span class="p">(</span><span class="n">col_encode</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;age&quot;</span><span class="p">,</span> <span class="s2">&quot;tumor-size&quot;</span><span class="p">,</span> <span class="s2">&quot;inv-nodes&quot;</span><span class="p">,</span> <span class="s2">&quot;Class&quot;</span><span class="p">],</span>
                                                    <span class="n">categories</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;age&quot;</span><span class="p">:</span><span class="n">age_order</span><span class="p">,</span>
                                                                            <span class="s2">&quot;tumor-size&quot;</span><span class="p">:</span><span class="n">tumor_size_order</span><span class="p">,</span>
                                                                            <span class="s2">&quot;inv-nodes&quot;</span><span class="p">:</span><span class="n">inv_nodes_order</span><span class="p">}</span>
                                            <span class="p">)</span>
<span class="n">enc_ord</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">proc_df</span> <span class="o">=</span> <span class="n">enc_ord</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Encode the remaining categorical columns using One-Hot Encoding</span>
<span class="n">enc_ohe</span> <span class="o">=</span> <span class="n">dp</span><span class="o">.</span><span class="n">EncoderOHE</span><span class="p">()</span>
<span class="n">enc_ohe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">proc_df</span><span class="p">)</span>
<span class="n">proc_df</span> <span class="o">=</span> <span class="n">enc_ohe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">proc_df</span><span class="p">)</span>
<span class="n">proc_df</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
No columns specified for encoding. These columns have been automatically identfied as the following:
[&#39;menopause&#39;, &#39;node-caps&#39;, &#39;breast&#39;, &#39;breast-quad&#39;, &#39;irradiat&#39;]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Class</th>
      <th>age</th>
      <th>tumor-size</th>
      <th>inv-nodes</th>
      <th>deg-malig</th>
      <th>menopause_lt40</th>
      <th>menopause_premeno</th>
      <th>node-caps_yes</th>
      <th>node-caps_nan</th>
      <th>breast_right</th>
      <th>breast-quad_left_low</th>
      <th>breast-quad_left_up</th>
      <th>breast-quad_right_low</th>
      <th>breast-quad_right_up</th>
      <th>breast-quad_nan</th>
      <th>irradiat_yes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>1</td>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>2</td>
      <td>3</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>2</td>
      <td>3</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>4</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>281</th>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>282</th>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>283</th>
      <td>1</td>
      <td>4</td>
      <td>3</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>284</th>
      <td>1</td>
      <td>2</td>
      <td>5</td>
      <td>4</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>285</th>
      <td>1</td>
      <td>3</td>
      <td>5</td>
      <td>4</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>286 rows × 16 columns</p>
</div></div>
</div>
<p>We can now check that our dataset has only numerical columns in it.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">proc_df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 286 entries, 0 to 285
Data columns (total 16 columns):
 #   Column                 Non-Null Count  Dtype
---  ------                 --------------  -----
 0   Class                  286 non-null    int64
 1   age                    286 non-null    int64
 2   tumor-size             286 non-null    int64
 3   inv-nodes              286 non-null    int64
 4   deg-malig              286 non-null    int64
 5   menopause_lt40         286 non-null    int32
 6   menopause_premeno      286 non-null    int32
 7   node-caps_yes          286 non-null    int32
 8   node-caps_nan          286 non-null    int32
 9   breast_right           286 non-null    int32
 10  breast-quad_left_low   286 non-null    int32
 11  breast-quad_left_up    286 non-null    int32
 12  breast-quad_right_low  286 non-null    int32
 13  breast-quad_right_up   286 non-null    int32
 14  breast-quad_nan        286 non-null    int32
 15  irradiat_yes           286 non-null    int32
dtypes: int32(11), int64(5)
memory usage: 23.6 KB
</pre></div></div>
</div>
</section>
<section id="Impute-Missing-Data-and-Split-Dataset">
<h3>Impute Missing Data and Split Dataset<a class="headerlink" href="#Impute-Missing-Data-and-Split-Dataset" title="Permalink to this heading"></a></h3>
<p>The next step consists on doing the following:</p>
<ul class="simple">
<li><p>split the dataset into train and test sets;</p></li>
<li><p>impute any missing data (if any).</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">test_y</span> <span class="o">=</span> <span class="n">split_data</span><span class="p">(</span><span class="n">proc_df</span><span class="p">,</span> <span class="n">label_col</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>

<span class="n">imputer</span> <span class="o">=</span> <span class="n">dp</span><span class="o">.</span><span class="n">BasicImputer</span><span class="p">()</span>
<span class="n">imputer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
<span class="n">train_x</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
<span class="n">test_x</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>
<span class="n">train_x</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
No columns specified for imputation. These columns have been automatically identified:
[]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>tumor-size</th>
      <th>inv-nodes</th>
      <th>deg-malig</th>
      <th>menopause_lt40</th>
      <th>menopause_premeno</th>
      <th>node-caps_yes</th>
      <th>node-caps_nan</th>
      <th>breast_right</th>
      <th>breast-quad_left_low</th>
      <th>breast-quad_left_up</th>
      <th>breast-quad_right_low</th>
      <th>breast-quad_right_up</th>
      <th>breast-quad_nan</th>
      <th>irradiat_yes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>165</th>
      <td>2</td>
      <td>3</td>
      <td>4</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>79</th>
      <td>2</td>
      <td>4</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>278</th>
      <td>3</td>
      <td>6</td>
      <td>2</td>
      <td>3</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>247</th>
      <td>3</td>
      <td>5</td>
      <td>6</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>248</th>
      <td>4</td>
      <td>6</td>
      <td>5</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>217</th>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>135</th>
      <td>1</td>
      <td>3</td>
      <td>4</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>258</th>
      <td>3</td>
      <td>5</td>
      <td>5</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>78</th>
      <td>3</td>
      <td>4</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>164</th>
      <td>4</td>
      <td>4</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>214 rows × 15 columns</p>
</div></div>
</div>
<p>As we can see, the dataset didn’t have any missing values. Therefore, the BasicImputer didn’t do anything.</p>
</section>
</section>
<section id="3---Baseline-Models">
<h2>3 - Baseline Models<a class="headerlink" href="#3---Baseline-Models" title="Permalink to this heading"></a></h2>
<p>In the following cells, we train different models and plot their results over the test set. These models will be considered our baseline models. We will test 2 models as our baseline: XGBoost and K-Nearest Neighbors (KNN).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">train_model_plot_results</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;xgb&quot;</span><span class="p">,</span> <span class="n">train_result</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">plot_pr</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

TEST SET:

[[26 25]
 [ 4 17]]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../_images/notebooks_dataprocessing_case_study_case1_19_1.png" src="../../../_images/notebooks_dataprocessing_case_study_case1_19_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
ROC AUC: 0.704014939309057
Precision: 0.6357142857142857
Recall: 0.6596638655462185
F1: 0.5908289241622575
Accuracy: 0.5972222222222222
Optimal Threshold (ROC curve): 0.2437402755022049
Optimal Threshold (Precision x Recall curve): 0.2437402755022049
Threshold used: 0.2437402755022049
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">train_model_plot_results</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;knn&quot;</span><span class="p">,</span> <span class="n">train_result</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">plot_pr</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

TEST SET:

[[19 32]
 [ 4 17]]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../_images/notebooks_dataprocessing_case_study_case1_20_1.png" src="../../../_images/notebooks_dataprocessing_case_study_case1_20_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
ROC AUC: 0.6087768440709618
Precision: 0.5865128660159716
Recall: 0.5910364145658263
F1: 0.49961389961389957
Accuracy: 0.5
Optimal Threshold (ROC curve): 0.2
Optimal Threshold (Precision x Recall curve): 0.2
Threshold used: 0.2
</pre></div></div>
</div>
</section>
<section id="4---Feature-Selection">
<h2>4 - Feature Selection<a class="headerlink" href="#4---Feature-Selection" title="Permalink to this heading"></a></h2>
<p>From this point on, we will try to improve (even if slightly) the results of the baseline models. But before jumping into these improvements, an important note: there is some randomness involved in the training process we showed so far due to two factors:</p>
<ul class="simple">
<li><p>the train and test split;</p></li>
<li><p>the model’s training process might involve some randomness.</p></li>
</ul>
<p>Therefore, if you re-run this notebook with different <code class="docutils literal notranslate"><span class="pre">SEED</span></code> values, you most probably will get different results. Given the small size of the dataset being used here, the split between train and test sets can be crucial for getting good results. This means that some seed values might have results considerably better than others. Keep that in mind when looking through these results and testing different seeds (try commenting the cell where we fix the random seeds to check how the results
vary). To really test the efficiency of the preprocessing steps shown here, we could run the split and train steps several times and record the mean (and standard deviation) of the results (auc, f1, etc.). This would give us a more powerful result. We encourage the interested user to check the notebook called <strong>notebooks/case_study/case1_stat.ipynb</strong>, which is a notebook where we perform the test previously described.</p>
<p>Now, let’s get back to our more simple experiments. Since we are using the same train and test split used by the baseline models, then we are good to go. Our first preprocessing (not considering the encoding part and the imputations, since those are mandatory to run the baseline models) is feature selection. Here, we will try the feature selection using the CatBoost model by using the <strong>CatBoostSelection</strong> class. Remember that we must pass the training set to the fit method, and then call the
transform method over the training and test sets. This way we don’t use any information of the test set for this step, avoiding data contamination.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feat_sel</span> <span class="o">=</span> <span class="n">dp</span><span class="o">.</span><span class="n">CatBoostSelection</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">feat_sel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">train_x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">train_y</span><span class="p">)</span>
<span class="n">train_x_sel</span> <span class="o">=</span> <span class="n">feat_sel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
<span class="n">test_x_sel</span> <span class="o">=</span> <span class="n">feat_sel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/matheus/miniconda3/envs/rai/lib/python3.9/site-packages/catboost/core.py:1222: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.
  self._init_pool(data, label, cat_features, text_features, embedding_features, pairs, weight,
</pre></div></div>
</div>
<p>Let’s print the selected features:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feat_sel</span><span class="o">.</span><span class="n">get_selected_features</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;tumor-size&#39;,
 &#39;inv-nodes&#39;,
 &#39;deg-malig&#39;,
 &#39;menopause_lt40&#39;,
 &#39;node-caps_nan&#39;,
 &#39;breast-quad_right_up&#39;,
 &#39;breast-quad_nan&#39;]
</pre></div></div>
</div>
<p>Now, let’s re-train the KNN model and see how the feature selection preprocessing step affects the results:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">train_model_plot_results</span><span class="p">(</span><span class="n">train_x_sel</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">test_x_sel</span><span class="p">,</span> <span class="n">test_y</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;knn&quot;</span><span class="p">,</span> <span class="n">train_result</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">plot_pr</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

TEST SET:

[[45  6]
 [14  7]]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../_images/notebooks_dataprocessing_case_study_case1_26_1.png" src="../../../_images/notebooks_dataprocessing_case_study_case1_26_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
ROC AUC: 0.6321195144724556
Precision: 0.6505867014341591
Recall: 0.6078431372549019
F1: 0.6149732620320855
Accuracy: 0.7222222222222222
Optimal Threshold (ROC curve): 0.6
Optimal Threshold (Precision x Recall curve): 0.2
Threshold used: 0.6
</pre></div></div>
</div>
<p>Looking at the confusion matrix and comparing it to the baseline KNN model, we can see that the True Positives and True Negatives are now flipped. However, we did get an improvement on the other metrics. Therefore, using feature selection managed to improve the results while using less data (we are now using only 7 columns instead of 9).</p>
</section>
<section id="5---Synthetic-Data">
<h2>5 - Synthetic Data<a class="headerlink" href="#5---Synthetic-Data" title="Permalink to this heading"></a></h2>
<p>The next preprocessing step we will test is creating synthetic data. We will start by using SMOTE and its variations.</p>
<section id="imblearn-Library">
<h3>imblearn Library<a class="headerlink" href="#imblearn-Library" title="Permalink to this heading"></a></h3>
<p>The imblearn library implements several variations of SMOTE, a over sampling strategy, as well as some under sampling mehtods, such as TOMEK Links. The class <strong>Rebalance</strong>, present in the <strong>dataprocessing</strong> library, encapsulates the imblearn library and automates certain processes. For example, we don’t need to specify which version of SMOTE we want to use. We simply provide the dataset and specify the amount of new data we want, and the class <strong>Rebalance</strong> will do the rest: it will check the
dataset and decide the best SMOTE variation to use, apply any under sampling method if requested, and run any preprocessing step if necessary (such as imputation). The user can also explicitly choose which SMOTE version they want by instantiating a SMOTE object (from imblearn) and passing it as a parameter to the <strong>Rebalance</strong> class. The same applies to the under sampling method.</p>
<p>Here, we use the default options provided by the <strong>Rebalance</strong> class regarding the SMOTE method. We choose to not use any under sampling method and we also specify explicitly the number of instances we want for the different values in the Y column.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_y</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0    150
1     64
Name: Class, dtype: int64
</pre></div></div>
</div>
<p>Since we got an improved performance when using feature selection, we’ll use our new dataset containing only the selected features in the following experiments. Note that these datasets are <code class="docutils literal notranslate"><span class="pre">train_x</span></code> and <code class="docutils literal notranslate"><span class="pre">test_x</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rebalance</span> <span class="o">=</span> <span class="n">dp</span><span class="o">.</span><span class="n">Rebalance</span><span class="p">(</span>
                            <span class="n">X</span><span class="o">=</span><span class="n">train_x_sel</span><span class="p">,</span>
                            <span class="n">y</span><span class="o">=</span><span class="n">train_y</span><span class="p">,</span>
                            <span class="n">strategy_over</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="mi">150</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">90</span><span class="p">},</span>
                            <span class="n">over_sampler</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">under_sampler</span><span class="o">=</span><span class="kc">False</span>
                    <span class="p">)</span>
<span class="n">train_x_res</span><span class="p">,</span> <span class="n">train_y_res</span> <span class="o">=</span> <span class="n">rebalance</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">()</span>
<span class="n">train_y_res</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
No columns specified for imputation. These columns have been automatically identified:
[]
Running oversampling...
...finished
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0    150
1     90
Name: Class, dtype: int64
</pre></div></div>
</div>
<p>We can now retrain the KNN model using the new dataset with oversampling:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">train_model_plot_results</span><span class="p">(</span><span class="n">train_x_res</span><span class="p">,</span> <span class="n">train_y_res</span><span class="p">,</span> <span class="n">test_x_sel</span><span class="p">,</span> <span class="n">test_y</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;knn&quot;</span><span class="p">,</span> <span class="n">train_result</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">plot_pr</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

TEST SET:

[[44  7]
 [12  9]]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../_images/notebooks_dataprocessing_case_study_case1_32_1.png" src="../../../_images/notebooks_dataprocessing_case_study_case1_32_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
ROC AUC: 0.645658263305322
Precision: 0.6741071428571428
Recall: 0.6456582633053222
F1: 0.6544581965142713
Accuracy: 0.7361111111111112
Optimal Threshold (ROC curve): 0.6
Optimal Threshold (Precision x Recall curve): 0.6
Threshold used: 0.6
</pre></div></div>
</div>
<p>As we can see here, the oversampling managed to improve the results for the test set even further (compared to the feature selection step).</p>
</section>
<section id="Creating-Artificial-Data-using-Deep-Learning">
<h3>Creating Artificial Data using Deep Learning<a class="headerlink" href="#Creating-Artificial-Data-using-Deep-Learning" title="Permalink to this heading"></a></h3>
<p>Instead of using SMOTE to do the over sampling, we can also use Generator models to create artificial data similar to the ones observed in the training dataset.</p>
<section id="CTGAN">
<h4>CTGAN<a class="headerlink" href="#CTGAN" title="Permalink to this heading"></a></h4>
<p>In the next cell, we use the <strong>Synthesizer</strong> class to create artificial data using the CTGAN model. Similarly to what we’ve done in the <strong>Rebalance</strong> experiment, we’ll use the datasets produced by the feature selection step. We can also try training the CTGAN for more epochs and see how this affects the results.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">synth</span> <span class="o">=</span> <span class="n">dp</span><span class="o">.</span><span class="n">Synthesizer</span><span class="p">(</span>
                            <span class="n">X</span><span class="o">=</span><span class="n">train_x_sel</span><span class="p">,</span>
                            <span class="n">y</span><span class="o">=</span><span class="n">train_y</span><span class="p">,</span>
                            <span class="n">epochs</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span>
                            <span class="n">model</span><span class="o">=</span><span class="s2">&quot;ctgan&quot;</span><span class="p">,</span>
                            <span class="n">load_existing</span><span class="o">=</span><span class="kc">False</span>
                    <span class="p">)</span>
<span class="n">synth</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">conditions</span> <span class="o">=</span> <span class="p">{</span><span class="n">label_col</span><span class="p">:</span><span class="mi">1</span><span class="p">}</span>
<span class="n">syn_train_x</span><span class="p">,</span> <span class="n">syn_train_y</span> <span class="o">=</span> <span class="n">synth</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">train_x_sel</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">train_y</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">conditions</span><span class="o">=</span><span class="n">conditions</span><span class="p">)</span>
<span class="n">syn_train_y</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/matheus/miniconda3/envs/rai/lib/python3.9/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (10). Possibly due to duplicate points in X.
  cluster.KMeans(
/home/matheus/miniconda3/envs/rai/lib/python3.9/site-packages/sklearn/mixture/_base.py:131: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.
  cluster.KMeans(
/home/matheus/miniconda3/envs/rai/lib/python3.9/site-packages/ctgan/data_transformer.py:111: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data[column_name] = data[column_name].to_numpy().flatten()
/home/matheus/miniconda3/envs/rai/lib/python3.9/site-packages/ctgan/data_transformer.py:111: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data[column_name] = data[column_name].to_numpy().flatten()
/home/matheus/miniconda3/envs/rai/lib/python3.9/site-packages/ctgan/data_transformer.py:111: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data[column_name] = data[column_name].to_numpy().flatten()
Sampling conditions:   0%|          | 0/20 [00:00&lt;?, ?it/s]/home/matheus/miniconda3/envs/rai/lib/python3.9/site-packages/sdv/tabular/base.py:608: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don&#39;t supply a list with a single grouper to avoid this warning.
  for group, dataframe in grouped_conditions:
/home/matheus/miniconda3/envs/rai/lib/python3.9/site-packages/sdv/tabular/base.py:639: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don&#39;t supply a list with a single grouper to avoid this warning.
  for transformed_group, transformed_dataframe in transformed_groups:
/home/matheus/miniconda3/envs/rai/lib/python3.9/site-packages/ctgan/data_transformer.py:149: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`
  data.iloc[:, 1] = np.argmax(column_data[:, 1:], axis=1)
/home/matheus/miniconda3/envs/rai/lib/python3.9/site-packages/ctgan/data_transformer.py:149: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`
  data.iloc[:, 1] = np.argmax(column_data[:, 1:], axis=1)
/home/matheus/miniconda3/envs/rai/lib/python3.9/site-packages/ctgan/data_transformer.py:149: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`
  data.iloc[:, 1] = np.argmax(column_data[:, 1:], axis=1)
/home/matheus/miniconda3/envs/rai/lib/python3.9/site-packages/ctgan/data_transformer.py:149: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`
  data.iloc[:, 1] = np.argmax(column_data[:, 1:], axis=1)
/home/matheus/miniconda3/envs/rai/lib/python3.9/site-packages/ctgan/data_transformer.py:149: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`
  data.iloc[:, 1] = np.argmax(column_data[:, 1:], axis=1)
/home/matheus/miniconda3/envs/rai/lib/python3.9/site-packages/ctgan/data_transformer.py:149: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`
  data.iloc[:, 1] = np.argmax(column_data[:, 1:], axis=1)
/home/matheus/miniconda3/envs/rai/lib/python3.9/site-packages/ctgan/data_transformer.py:149: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`
  data.iloc[:, 1] = np.argmax(column_data[:, 1:], axis=1)
/home/matheus/miniconda3/envs/rai/lib/python3.9/site-packages/ctgan/data_transformer.py:149: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`
  data.iloc[:, 1] = np.argmax(column_data[:, 1:], axis=1)
/home/matheus/miniconda3/envs/rai/lib/python3.9/site-packages/ctgan/data_transformer.py:149: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`
  data.iloc[:, 1] = np.argmax(column_data[:, 1:], axis=1)
Sampling conditions: 100%|██████████| 20/20 [00:00&lt;00:00, 215.10it/s]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0    150
1     84
Name: Class, dtype: int64
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">train_model_plot_results</span><span class="p">(</span><span class="n">syn_train_x</span><span class="p">,</span> <span class="n">syn_train_y</span><span class="p">,</span> <span class="n">test_x_sel</span><span class="p">,</span> <span class="n">test_y</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;knn&quot;</span><span class="p">,</span> <span class="n">train_result</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">plot_pr</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

TEST SET:

[[38 13]
 [ 8 13]]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../_images/notebooks_dataprocessing_case_study_case1_35_1.png" src="../../../_images/notebooks_dataprocessing_case_study_case1_35_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
ROC AUC: 0.6862745098039216
Precision: 0.6630434782608696
Recall: 0.6820728291316527
F1: 0.6683483220004387
Accuracy: 0.7083333333333334
Optimal Threshold (ROC curve): 0.4
Optimal Threshold (Precision x Recall curve): 0.4
Threshold used: 0.4
</pre></div></div>
</div>
<p>Comparing the results to the feature selection step, we notice that the results obtained here are worse for all metrics. Therefore, in this scenario, the CTGAN didn’t manage to improve the performance as the <strong>Rebalance</strong> class.</p>
<p>Once again, remember to test different seed values and see how the results will be different.</p>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../module_tests/model_test.html" class="btn btn-neutral float-left" title="Simple Example" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="case2.html" class="btn btn-neutral float-right" title="Case Study 2" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Microsoft.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>