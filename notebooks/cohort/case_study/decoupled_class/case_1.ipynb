{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoupled Classifiers Case Study 1\n",
    "For the first case study, we'll highlight the benefits of using the decoupled classifiers over different cohorts of the data. This module implements techniques for searching and combining cohorts to optimize for different definitions of group fairness based on the approach presented in the paper [Decoupled classifiers for group-fair and efficient machine learning](https://www.microsoft.com/en-us/research/publication/decoupled-classifiers-for-group-fair-and-efficient-machine-learning/).\n",
    "\n",
    "The techniques implemented in this module work with the ``Cohort`` module of this library to fit an estimator over each cohort while leveraging transfer learning and other optimization techniques for minority cohorts when the data for such cohorts is not sufficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from raimitigations.utils import split_data\n",
    "import raimitigations.dataprocessing as dp\n",
    "from raimitigations.cohort import DecoupledClass, CohortDefinition, CohortManager, fetch_cohort_results\n",
    "from sklearn.pipeline import Pipeline\n",
    "SEED = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this case study, we will recreate and use a synthetic dataset created as part of [Cohort case study 1](../case_1.ipynb) to showcase the additional techniques this module can use to optimize fairness and performance over cohorts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_country_df(samples: int, sectors: dict, country_name: str):\n",
    "    df = None\n",
    "    for key in sectors.keys():\n",
    "        size = int(samples * sectors[key][\"prob_occur\"])\n",
    "        invest = np.random.uniform(low=sectors[key][\"min\"], high=sectors[key][\"max\"], size=size)\n",
    "        min_invest = min(invest)\n",
    "        max_invest = max(invest)\n",
    "        range_invest = max_invest - min_invest\n",
    "        bankrupt_th = sectors[key][\"prob_success\"] * range_invest\n",
    "        inverted_behavior = sectors[key][\"inverted_behavior\"]\n",
    "        bankrupt = []\n",
    "        for i in range(invest.shape[0]):\n",
    "            inst_class = 1\n",
    "            if invest[i] > bankrupt_th:\n",
    "                inst_class = 0\n",
    "            if inverted_behavior:\n",
    "                inst_class = int(not inst_class)\n",
    "            bankrupt.append(inst_class)\n",
    "        noise_ind = np.random.choice(range(size), int(size*0.05), replace=False)\n",
    "        for ind in noise_ind:\n",
    "            bankrupt[ind] = int(not bankrupt[ind])\n",
    "        noise_ind = np.random.choice(range(size), int(size*0.1), replace=False)\n",
    "        for ind in noise_ind:\n",
    "            invest[ind] = np.nan\n",
    "        \n",
    "        country_col = [country_name for _ in range(size)]\n",
    "        sector_col = [key for _ in range(size)]\n",
    "        df_sector = pd.DataFrame({\n",
    "            \"investment\":invest,\n",
    "            \"sector\":sector_col,\n",
    "            \"country\":country_col,\n",
    "            \"bankrupt\":bankrupt\n",
    "        })\n",
    "        \n",
    "        if df is None:\n",
    "            df = df_sector\n",
    "        else:\n",
    "            df = pd.concat([df, df_sector], axis=0)\n",
    "    return df\n",
    "\n",
    "def create_df_multiple_distributions(samples: list):\n",
    "    sectors_c1 = {\n",
    "        \"s1\": {\"prob_occur\":0.5, \"prob_success\":0.99, \"inverted_behavior\":False, \"min\":2e6, \"max\":1e7},\n",
    "        \"s2\": {\"prob_occur\":0.1, \"prob_success\":0.2, \"inverted_behavior\":False, \"min\":1e7, \"max\":1.5e9},\n",
    "        \"s3\": {\"prob_occur\":0.1, \"prob_success\":0.9, \"inverted_behavior\":True, \"min\":1e9, \"max\":1e10},\n",
    "        \"s4\": {\"prob_occur\":0.3, \"prob_success\":0.7, \"inverted_behavior\":False, \"min\":4e10, \"max\":9e13},\n",
    "    }\n",
    "    sectors_c2 = {\n",
    "        \"s1\": {\"prob_occur\":0.1, \"prob_success\":0.6, \"inverted_behavior\":True, \"min\":1e3, \"max\":5e3},\n",
    "        \"s2\": {\"prob_occur\":0.3, \"prob_success\":0.9, \"inverted_behavior\":False, \"min\":1e5, \"max\":1.5e6},\n",
    "        \"s3\": {\"prob_occur\":0.5, \"prob_success\":0.3, \"inverted_behavior\":False, \"min\":5e4, \"max\":3e5},\n",
    "        \"s4\": {\"prob_occur\":0.1, \"prob_success\":0.8, \"inverted_behavior\":False, \"min\":1e6, \"max\":1e7},\n",
    "    }\n",
    "    sectors_c3 = {\n",
    "        \"s1\": {\"prob_occur\":0.3, \"prob_success\":0.9, \"inverted_behavior\":False, \"min\":3e2, \"max\":6e2},\n",
    "        \"s2\": {\"prob_occur\":0.6, \"prob_success\":0.7, \"inverted_behavior\":False, \"min\":5e3, \"max\":9e3},\n",
    "        \"s3\": {\"prob_occur\":0.07, \"prob_success\":0.6, \"inverted_behavior\":False, \"min\":4e3, \"max\":2e4},\n",
    "        \"s4\": {\"prob_occur\":0.03, \"prob_success\":0.1, \"inverted_behavior\":True, \"min\":6e5, \"max\":1.3e6},\n",
    "    }\n",
    "    countries = {\n",
    "        \"A\":{\"sectors\":sectors_c1, \"sample_rate\":0.85},\n",
    "        \"B\":{\"sectors\":sectors_c2, \"sample_rate\":0.05},\n",
    "        \"C\":{\"sectors\":sectors_c2, \"sample_rate\":0.1}\n",
    "    }\n",
    "    df = None\n",
    "    for key in countries.keys():\n",
    "        n_sample = int(samples * countries[key][\"sample_rate\"])\n",
    "        df_c = _create_country_df(n_sample, countries[key][\"sectors\"], key)\n",
    "        if df is None:\n",
    "            df = df_c\n",
    "        else:\n",
    "            df = pd.concat([df, df_c], axis=0)\n",
    "    \n",
    "    idx = pd.Index([i for i in range(df.shape[0])])\n",
    "    df = df.set_index(idx)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: this dataset details if a company has gone bankrupt (class 1) or hasn't (class 0):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>investment</th>\n",
       "      <th>sector</th>\n",
       "      <th>country</th>\n",
       "      <th>bankrupt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.405851e+06</td>\n",
       "      <td>s1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.357697e+06</td>\n",
       "      <td>s1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.746429e+06</td>\n",
       "      <td>s1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.152158e+06</td>\n",
       "      <td>s1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>s1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>4.226512e+06</td>\n",
       "      <td>s4</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3.566758e+06</td>\n",
       "      <td>s4</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9.281006e+06</td>\n",
       "      <td>s4</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>5.770378e+06</td>\n",
       "      <td>s4</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>3.661511e+06</td>\n",
       "      <td>s4</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        investment sector country  bankrupt\n",
       "0     7.405851e+06     s1       A         1\n",
       "1     2.357697e+06     s1       A         1\n",
       "2     4.746429e+06     s1       A         1\n",
       "3     7.152158e+06     s1       A         1\n",
       "4              NaN     s1       A         1\n",
       "...            ...    ...     ...       ...\n",
       "9995  4.226512e+06     s4       C         1\n",
       "9996  3.566758e+06     s4       C         0\n",
       "9997  9.281006e+06     s4       C         0\n",
       "9998  5.770378e+06     s4       C         1\n",
       "9999  3.661511e+06     s4       C         1\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(51)\n",
    "df = create_df_multiple_distributions(10000)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(df, label=\"bankrupt\", test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    #model = DecisionTreeClassifier(max_features=\"sqrt\")\n",
    "    model = LGBMClassifier(random_state=SEED)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Case\n",
    "In order to demonstrate the additional benefits of the decoupled classifiers, we start with the `CohortManager` class as the baseline.\n",
    "\n",
    "Now, let's look at the metrics and performance of the *\"sector\"* and *\"country\"* cohorts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort</th>\n",
       "      <th>cht_query</th>\n",
       "      <th>roc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>threshold</th>\n",
       "      <th>num_pos</th>\n",
       "      <th>%_pos</th>\n",
       "      <th>cht_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>0.947905</td>\n",
       "      <td>0.929772</td>\n",
       "      <td>0.921173</td>\n",
       "      <td>0.924828</td>\n",
       "      <td>0.927667</td>\n",
       "      <td>0.535672</td>\n",
       "      <td>1829</td>\n",
       "      <td>0.609667</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cohort_0</td>\n",
       "      <td>(`sector` == \"s1\")</td>\n",
       "      <td>0.933652</td>\n",
       "      <td>0.863698</td>\n",
       "      <td>0.896230</td>\n",
       "      <td>0.876748</td>\n",
       "      <td>0.893650</td>\n",
       "      <td>0.783542</td>\n",
       "      <td>863</td>\n",
       "      <td>0.660291</td>\n",
       "      <td>1307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cohort_1</td>\n",
       "      <td>(`sector` == \"s2\")</td>\n",
       "      <td>0.942994</td>\n",
       "      <td>0.931929</td>\n",
       "      <td>0.916137</td>\n",
       "      <td>0.921523</td>\n",
       "      <td>0.924084</td>\n",
       "      <td>0.381770</td>\n",
       "      <td>147</td>\n",
       "      <td>0.384817</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cohort_2</td>\n",
       "      <td>(`sector` == \"s3\")</td>\n",
       "      <td>0.860066</td>\n",
       "      <td>0.716087</td>\n",
       "      <td>0.787660</td>\n",
       "      <td>0.738242</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>0.156317</td>\n",
       "      <td>133</td>\n",
       "      <td>0.270325</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cohort_3</td>\n",
       "      <td>(`sector` == \"s4\")</td>\n",
       "      <td>0.925276</td>\n",
       "      <td>0.859874</td>\n",
       "      <td>0.885490</td>\n",
       "      <td>0.870424</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.724742</td>\n",
       "      <td>536</td>\n",
       "      <td>0.654457</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cohort           cht_query       roc  precision    recall        f1  \\\n",
       "0       all                 all  0.947905   0.929772  0.921173  0.924828   \n",
       "1  cohort_0  (`sector` == \"s1\")  0.933652   0.863698  0.896230  0.876748   \n",
       "2  cohort_1  (`sector` == \"s2\")  0.942994   0.931929  0.916137  0.921523   \n",
       "3  cohort_2  (`sector` == \"s3\")  0.860066   0.716087  0.787660  0.738242   \n",
       "4  cohort_3  (`sector` == \"s4\")  0.925276   0.859874  0.885490  0.870424   \n",
       "\n",
       "   accuracy  threshold  num_pos     %_pos  cht_size  \n",
       "0  0.927667   0.535672     1829  0.609667      3000  \n",
       "1  0.893650   0.783542      863  0.660291      1307  \n",
       "2  0.924084   0.381770      147  0.384817       382  \n",
       "3  0.817073   0.156317      133  0.270325       492  \n",
       "4  0.886447   0.724742      536  0.654457       819  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BASELINE: \"sector\"\n",
    "cht_manager = CohortManager(\n",
    "    transform_pipe=[\n",
    "        dp.BasicImputer(verbose=False),\n",
    "        dp.DataMinMaxScaler(verbose=False),\n",
    "        dp.EncoderOHE(verbose=False),\n",
    "        get_model()\n",
    "    ],\n",
    "    cohort_col=[\"sector\"]\n",
    ")\n",
    "cht_manager.fit(X_train, y_train)\n",
    "pred_cht = cht_manager.predict_proba(X_test)\n",
    "\n",
    "pred_train = cht_manager.predict_proba(X_train)\n",
    "metrics_train, th_dict = fetch_cohort_results(X_train, y_train, pred_train, cohort_col=[\"sector\"], return_th_dict=True)\n",
    "fetch_cohort_results(X_test, y_test, pred_cht, cohort_col=[\"sector\"], fixed_th=th_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort</th>\n",
       "      <th>cht_query</th>\n",
       "      <th>roc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>threshold</th>\n",
       "      <th>num_pos</th>\n",
       "      <th>%_pos</th>\n",
       "      <th>cht_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>0.944930</td>\n",
       "      <td>0.924198</td>\n",
       "      <td>0.917583</td>\n",
       "      <td>0.920483</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.618757</td>\n",
       "      <td>1814</td>\n",
       "      <td>0.604667</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cohort_0</td>\n",
       "      <td>(`country` == \"A\")</td>\n",
       "      <td>0.945985</td>\n",
       "      <td>0.927582</td>\n",
       "      <td>0.917092</td>\n",
       "      <td>0.921732</td>\n",
       "      <td>0.926562</td>\n",
       "      <td>0.664861</td>\n",
       "      <td>1628</td>\n",
       "      <td>0.635938</td>\n",
       "      <td>2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cohort_1</td>\n",
       "      <td>(`country` == \"B\")</td>\n",
       "      <td>0.935107</td>\n",
       "      <td>0.869528</td>\n",
       "      <td>0.860549</td>\n",
       "      <td>0.864621</td>\n",
       "      <td>0.875817</td>\n",
       "      <td>0.500140</td>\n",
       "      <td>53</td>\n",
       "      <td>0.346405</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cohort_2</td>\n",
       "      <td>(`country` == \"C\")</td>\n",
       "      <td>0.934542</td>\n",
       "      <td>0.925572</td>\n",
       "      <td>0.928491</td>\n",
       "      <td>0.926472</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.340654</td>\n",
       "      <td>137</td>\n",
       "      <td>0.477352</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cohort           cht_query       roc  precision    recall        f1  \\\n",
       "0       all                 all  0.944930   0.924198  0.917583  0.920483   \n",
       "1  cohort_0  (`country` == \"A\")  0.945985   0.927582  0.917092  0.921732   \n",
       "2  cohort_1  (`country` == \"B\")  0.935107   0.869528  0.860549  0.864621   \n",
       "3  cohort_2  (`country` == \"C\")  0.934542   0.925572  0.928491  0.926472   \n",
       "\n",
       "   accuracy  threshold  num_pos     %_pos  cht_size  \n",
       "0  0.923333   0.618757     1814  0.604667      3000  \n",
       "1  0.926562   0.664861     1628  0.635938      2560  \n",
       "2  0.875817   0.500140       53  0.346405       153  \n",
       "3  0.926829   0.340654      137  0.477352       287  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BASELINE: \"country\"\n",
    "cht_manager = CohortManager(\n",
    "    transform_pipe=[\n",
    "        dp.BasicImputer(verbose=False),\n",
    "        dp.DataMinMaxScaler(verbose=False),\n",
    "        dp.EncoderOHE(verbose=False),\n",
    "        get_model()\n",
    "    ],\n",
    "    cohort_col=[\"country\"]\n",
    ")\n",
    "cht_manager.fit(X_train, y_train)\n",
    "pred_cht = cht_manager.predict_proba(X_test)\n",
    "\n",
    "pred_train = cht_manager.predict_proba(X_train)\n",
    "metrics_train, th_dict = fetch_cohort_results(X_train, y_train, pred_train, cohort_col=[\"country\"], return_th_dict=True)\n",
    "fetch_cohort_results(X_test, y_test, pred_cht, cohort_col=[\"country\"], fixed_th=th_dict)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `CohortManager` class in this case creates and trains a cohort for each unique value of these columns **regardless of label distribution and size of cohort**. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecoupledClass Techniques"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, what if we were to use the `DecoupledClass` to look at the same columns using the same pre-processing pipeline and estimator. \n",
    "\n",
    "Let's start with the *\"sector\"* column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL COHORTS\n",
      "cohort_0:\n",
      "\tSize: 3093\n",
      "\tQuery:\n",
      "\t\t(`sector` == \"s1\")\n",
      "\tValue Counts:\n",
      "\t\t1: 2169 (70.13%)\n",
      "\t\t0: 924 (29.87%)\n",
      "\tInvalid: False\n",
      "\n",
      "\n",
      "cohort_1:\n",
      "\tSize: 918\n",
      "\tQuery:\n",
      "\t\t(`sector` == \"s2\")\n",
      "\tValue Counts:\n",
      "\t\t0: 519 (56.54%)\n",
      "\t\t1: 399 (43.46%)\n",
      "\tInvalid: False\n",
      "\n",
      "\n",
      "cohort_2:\n",
      "\tSize: 1108\n",
      "\tQuery:\n",
      "\t\t(`sector` == \"s3\")\n",
      "\tValue Counts:\n",
      "\t\t0: 889 (80.23%)\n",
      "\t\t1: 219 (19.77%)\n",
      "\tInvalid: False\n",
      "\n",
      "\n",
      "cohort_3:\n",
      "\tSize: 1881\n",
      "\tQuery:\n",
      "\t\t(`sector` == \"s4\")\n",
      "\tValue Counts:\n",
      "\t\t1: 1307 (69.48%)\n",
      "\t\t0: 574 (30.52%)\n",
      "\tInvalid: False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessing = [dp.BasicImputer(verbose=False), dp.DataMinMaxScaler(verbose=False), dp.EncoderOHE(verbose=False)]\n",
    "\n",
    "dec_class = DecoupledClass(\n",
    "    cohort_col=['sector'],\n",
    "    transform_pipe=preprocessing,\n",
    "    estimator=get_model()\n",
    ")\n",
    "dec_class.fit(X_train, y_train)\n",
    "\n",
    "dec_class.print_cohorts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort</th>\n",
       "      <th>cht_query</th>\n",
       "      <th>roc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>threshold</th>\n",
       "      <th>num_pos</th>\n",
       "      <th>%_pos</th>\n",
       "      <th>cht_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>0.947905</td>\n",
       "      <td>0.929772</td>\n",
       "      <td>0.921173</td>\n",
       "      <td>0.924828</td>\n",
       "      <td>0.927667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1829</td>\n",
       "      <td>0.609667</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cohort_0</td>\n",
       "      <td>(`sector` == \"s1\")</td>\n",
       "      <td>0.933652</td>\n",
       "      <td>0.937394</td>\n",
       "      <td>0.886916</td>\n",
       "      <td>0.907627</td>\n",
       "      <td>0.928080</td>\n",
       "      <td>0.630641</td>\n",
       "      <td>994</td>\n",
       "      <td>0.760520</td>\n",
       "      <td>1307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cohort_1</td>\n",
       "      <td>(`sector` == \"s2\")</td>\n",
       "      <td>0.942994</td>\n",
       "      <td>0.931929</td>\n",
       "      <td>0.916137</td>\n",
       "      <td>0.921523</td>\n",
       "      <td>0.924084</td>\n",
       "      <td>0.381770</td>\n",
       "      <td>147</td>\n",
       "      <td>0.384817</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cohort_2</td>\n",
       "      <td>(`sector` == \"s3\")</td>\n",
       "      <td>0.860066</td>\n",
       "      <td>0.898785</td>\n",
       "      <td>0.851521</td>\n",
       "      <td>0.872572</td>\n",
       "      <td>0.928862</td>\n",
       "      <td>0.310128</td>\n",
       "      <td>76</td>\n",
       "      <td>0.154472</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cohort_3</td>\n",
       "      <td>(`sector` == \"s4\")</td>\n",
       "      <td>0.925276</td>\n",
       "      <td>0.941381</td>\n",
       "      <td>0.885875</td>\n",
       "      <td>0.907826</td>\n",
       "      <td>0.926740</td>\n",
       "      <td>0.474869</td>\n",
       "      <td>619</td>\n",
       "      <td>0.755800</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cohort           cht_query       roc  precision    recall        f1  \\\n",
       "0       all                 all  0.947905   0.929772  0.921173  0.924828   \n",
       "1  cohort_0  (`sector` == \"s1\")  0.933652   0.937394  0.886916  0.907627   \n",
       "2  cohort_1  (`sector` == \"s2\")  0.942994   0.931929  0.916137  0.921523   \n",
       "3  cohort_2  (`sector` == \"s3\")  0.860066   0.898785  0.851521  0.872572   \n",
       "4  cohort_3  (`sector` == \"s4\")  0.925276   0.941381  0.885875  0.907826   \n",
       "\n",
       "   accuracy  threshold  num_pos     %_pos  cht_size  \n",
       "0  0.927667   0.500000     1829  0.609667      3000  \n",
       "1  0.928080   0.630641      994  0.760520      1307  \n",
       "2  0.924084   0.381770      147  0.384817       382  \n",
       "3  0.928862   0.310128       76  0.154472       492  \n",
       "4  0.926740   0.474869      619  0.755800       819  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_dict = dec_class.get_threasholds_dict()\n",
    "pred = dec_class.predict_proba(X_test)\n",
    "fetch_cohort_results(X_test, y_test, pred, cohort_def=dec_class, fixed_th=th_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the 4 cohorts (one for each unique value of the column) are no different than the cohorts created by the `Cohort` module, the reason for that is that all 4 cohorts were not invalid. \n",
    "*An **invalid cohort** is defined as a cohort that has a size < `max(min_cohort_size, df.shape[0] * min_cohort_pct)` or is with a minority class (the label value with least occurrences) with an occurrence rate < `minority_min_rate`*.\n",
    "\n",
    "In the case of invalid cohorts, the `DecoupledClass` fit method uses a few techniques to create valid cohorts from these invalid ones. \n",
    "So how do we use the `DecoupledClass` to handle invalid cohorts? For the remainder of this case study, we'll explore the cohorts of the *\"country\"* column to demonstrate the latter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Invalid Cohorts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at merging invalid cohorts.\n",
    "This technique creates valid cohorts from invalid ones by choosing the smallest cohort different from the invalid cohort and merging the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL COHORTS\n",
      "cohort_0:\n",
      "\tSize: 5940\n",
      "\tQuery:\n",
      "\t\t(`country` == \"A\")\n",
      "\tValue Counts:\n",
      "\t\t1: 3612 (60.81%)\n",
      "\t\t0: 2328 (39.19%)\n",
      "\tInvalid: False\n",
      "\n",
      "\n",
      "cohort_1:\n",
      "\tSize: 1060\n",
      "\tQuery:\n",
      "\t\t((`country` == \"B\")) or ((`country` == \"C\"))\n",
      "\tValue Counts:\n",
      "\t\t0: 578 (54.53%)\n",
      "\t\t1: 482 (45.47%)\n",
      "\tInvalid: False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessing = [dp.BasicImputer(verbose=False), dp.DataMinMaxScaler(verbose=False), dp.EncoderOHE(verbose=False)]\n",
    "\n",
    "dec_class = DecoupledClass(\n",
    "    cohort_col=[\"country\"],\n",
    "    min_cohort_pct=0.15,\n",
    "    minority_min_rate=0.15,\n",
    "    transform_pipe=preprocessing,\n",
    "    estimator=get_model()\n",
    ")\n",
    "dec_class.fit(X_train, y_train)\n",
    "\n",
    "dec_class.print_cohorts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the *\"country\"* column above has created 2 cohorts. Initially, we might have expected 3 for each unique value (\"A\",\"B\",\"C\"), however, the `DecoupledClass` found invalid cohorts and performed a merge of the `(country==\"B\")` and `(country==\"C\")` cohorts to create a single valid one. Now let's see how does this setup perform over the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort</th>\n",
       "      <th>cht_query</th>\n",
       "      <th>roc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>threshold</th>\n",
       "      <th>num_pos</th>\n",
       "      <th>%_pos</th>\n",
       "      <th>cht_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>0.946290</td>\n",
       "      <td>0.927526</td>\n",
       "      <td>0.919864</td>\n",
       "      <td>0.923168</td>\n",
       "      <td>0.926000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1822</td>\n",
       "      <td>0.607333</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cohort_0</td>\n",
       "      <td>(`country` == \"A\")</td>\n",
       "      <td>0.945985</td>\n",
       "      <td>0.930449</td>\n",
       "      <td>0.916938</td>\n",
       "      <td>0.922738</td>\n",
       "      <td>0.927734</td>\n",
       "      <td>0.525770</td>\n",
       "      <td>1643</td>\n",
       "      <td>0.641797</td>\n",
       "      <td>2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cohort_1</td>\n",
       "      <td>((`country` == \"B\")) or ((`country` == \"C\"))</td>\n",
       "      <td>0.941379</td>\n",
       "      <td>0.919319</td>\n",
       "      <td>0.917429</td>\n",
       "      <td>0.918328</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.499605</td>\n",
       "      <td>183</td>\n",
       "      <td>0.415909</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cohort                                     cht_query       roc  \\\n",
       "0       all                                           all  0.946290   \n",
       "1  cohort_0                            (`country` == \"A\")  0.945985   \n",
       "2  cohort_1  ((`country` == \"B\")) or ((`country` == \"C\"))  0.941379   \n",
       "\n",
       "   precision    recall        f1  accuracy  threshold  num_pos     %_pos  \\\n",
       "0   0.927526  0.919864  0.923168  0.926000   0.500000     1822  0.607333   \n",
       "1   0.930449  0.916938  0.922738  0.927734   0.525770     1643  0.641797   \n",
       "2   0.919319  0.917429  0.918328  0.920455   0.499605      183  0.415909   \n",
       "\n",
       "   cht_size  \n",
       "0      3000  \n",
       "1      2560  \n",
       "2       440  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_dict = dec_class.get_threasholds_dict()\n",
    "pred = dec_class.predict_proba(X_test)\n",
    "fetch_cohort_results(X_test, y_test, pred, cohort_def=dec_class, fixed_th=th_dict)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the metrics of these merged cohorts to the baseline, it seems in this case that merging the invalid cohort `(country==\"B\")` with the cohort `(country==\"C\")` has a positive effect on `(country==\"B\")`, slightly improving the label distribution and therefore its accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's explore the other technique that distinguishes the decoupled classifiers, transfer learning. \n",
    "\n",
    "In this approach, when calling the `fit()` method with an invalid cohort, we use data from other cohorts (out-data), while weighing down these instances to create a valid cohort.\n",
    "\n",
    "In order to use transfer learning with the `DecoupledClass` module, we simply need to pass a `theta` value. `theta` can be a fixed float, a list of floats (the best value in the list is found using cross-validation), or a boolean `True` to use a default list of floats optimized using cross-validation. If you'd like to learn more about how we select out-data and how to use different types of theta with transfer learning, see the [tutorial notebook for the decoupled classifiers](../../decoupled.ipynb). \n",
    "\n",
    "Let's take a look at how transfer learning handles the invalid cohorts in our case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL COHORTS\n",
      "cohort_0:\n",
      "\tSize: 5940\n",
      "\tQuery:\n",
      "\t\t(`country` == \"A\")\n",
      "\tValue Counts:\n",
      "\t\t1: 3612 (60.81%)\n",
      "\t\t0: 2328 (39.19%)\n",
      "\tInvalid: False\n",
      "\n",
      "\n",
      "cohort_1:\n",
      "\tSize: 347\n",
      "\tQuery:\n",
      "\t\t(`country` == \"B\")\n",
      "\tValue Counts:\n",
      "\t\t0: 190 (54.76%)\n",
      "\t\t1: 157 (45.24%)\n",
      "\tInvalid: True\n",
      "\t\tCohorts used as outside data: ['cohort_0', 'cohort_2']\n",
      "\t\tTheta = 0.4\n",
      "\n",
      "\n",
      "cohort_2:\n",
      "\tSize: 713\n",
      "\tQuery:\n",
      "\t\t(`country` == \"C\")\n",
      "\tValue Counts:\n",
      "\t\t0: 388 (54.42%)\n",
      "\t\t1: 325 (45.58%)\n",
      "\tInvalid: True\n",
      "\t\tCohorts used as outside data: ['cohort_0', 'cohort_1']\n",
      "\t\tTheta = 0.6\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessing = [dp.BasicImputer(verbose=False), dp.DataMinMaxScaler(verbose=False), dp.EncoderOHE(verbose=False)]\n",
    "\n",
    "dec_class = DecoupledClass(\n",
    "    cohort_col=[\"country\"],\n",
    "    theta=True,\n",
    "    min_fold_size_theta=5,\n",
    "    min_cohort_pct=0.2,\n",
    "    minority_min_rate=0.15,\n",
    "    transform_pipe=preprocessing,\n",
    "    estimator=get_model()\n",
    ")\n",
    "\n",
    "dec_class.fit(X_train, y_train)\n",
    "\n",
    "dec_class.print_cohorts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort</th>\n",
       "      <th>cht_query</th>\n",
       "      <th>roc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>threshold</th>\n",
       "      <th>num_pos</th>\n",
       "      <th>%_pos</th>\n",
       "      <th>cht_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>0.947784</td>\n",
       "      <td>0.930492</td>\n",
       "      <td>0.921226</td>\n",
       "      <td>0.925124</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1834</td>\n",
       "      <td>0.611333</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cohort_0</td>\n",
       "      <td>(`country` == \"A\")</td>\n",
       "      <td>0.945985</td>\n",
       "      <td>0.930449</td>\n",
       "      <td>0.916938</td>\n",
       "      <td>0.922738</td>\n",
       "      <td>0.927734</td>\n",
       "      <td>0.525770</td>\n",
       "      <td>1643</td>\n",
       "      <td>0.641797</td>\n",
       "      <td>2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cohort_1</td>\n",
       "      <td>(`country` == \"B\")</td>\n",
       "      <td>0.953976</td>\n",
       "      <td>0.911828</td>\n",
       "      <td>0.923049</td>\n",
       "      <td>0.916697</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.475236</td>\n",
       "      <td>60</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cohort_2</td>\n",
       "      <td>(`country` == \"C\")</td>\n",
       "      <td>0.945566</td>\n",
       "      <td>0.922287</td>\n",
       "      <td>0.923322</td>\n",
       "      <td>0.922759</td>\n",
       "      <td>0.923345</td>\n",
       "      <td>0.594635</td>\n",
       "      <td>132</td>\n",
       "      <td>0.459930</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cohort           cht_query       roc  precision    recall        f1  \\\n",
       "0       all                 all  0.947784   0.930492  0.921226  0.925124   \n",
       "1  cohort_0  (`country` == \"A\")  0.945985   0.930449  0.916938  0.922738   \n",
       "2  cohort_1  (`country` == \"B\")  0.953976   0.911828  0.923049  0.916697   \n",
       "3  cohort_2  (`country` == \"C\")  0.945566   0.922287  0.923322  0.922759   \n",
       "\n",
       "   accuracy  threshold  num_pos     %_pos  cht_size  \n",
       "0  0.928000   0.500000     1834  0.611333      3000  \n",
       "1  0.927734   0.525770     1643  0.641797      2560  \n",
       "2  0.921569   0.475236       60  0.392157       153  \n",
       "3  0.923345   0.594635      132  0.459930       287  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_dict = dec_class.get_threasholds_dict()\n",
    "pred = dec_class.predict_proba(X_test)\n",
    "fetch_cohort_results(X_test, y_test, pred, cohort_def=dec_class, fixed_th=th_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing these results to the metrics of the baseline valid/invalid cohorts, it seems that transfer learning might have made a positive but less noticeable difference for cohort `(country==\"B\")` in this case."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Fairness Metrics\n",
    "\n",
    "Lastly, `DecoupledClass` offers the option to optimize all models according to a fairness metric. We have the option for a fairness metric between *\"balanced\"*, *\"num_parity\"* and *\"dem_parity\"*, for a more detailed look on these different metrics and how to use them, see [the tutorial notebook for the decoupled classfiers](../../decoupled.ipynb). \n",
    "\n",
    "In this case, we'll explore this feature over our cohorts using the *\"dem_parity\"* metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort</th>\n",
       "      <th>cht_query</th>\n",
       "      <th>roc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>threshold</th>\n",
       "      <th>num_pos</th>\n",
       "      <th>%_pos</th>\n",
       "      <th>cht_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>0.946290</td>\n",
       "      <td>0.927526</td>\n",
       "      <td>0.919864</td>\n",
       "      <td>0.923168</td>\n",
       "      <td>0.926000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1822</td>\n",
       "      <td>0.607333</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cohort_0</td>\n",
       "      <td>(`country` == \"A\")</td>\n",
       "      <td>0.945985</td>\n",
       "      <td>0.886854</td>\n",
       "      <td>0.902609</td>\n",
       "      <td>0.891498</td>\n",
       "      <td>0.894531</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>1420</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cohort_1</td>\n",
       "      <td>((`country` == \"B\")) or ((`country` == \"C\"))</td>\n",
       "      <td>0.941379</td>\n",
       "      <td>0.845511</td>\n",
       "      <td>0.852320</td>\n",
       "      <td>0.838335</td>\n",
       "      <td>0.838636</td>\n",
       "      <td>0.151803</td>\n",
       "      <td>235</td>\n",
       "      <td>0.534091</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cohort                                     cht_query       roc  \\\n",
       "0       all                                           all  0.946290   \n",
       "1  cohort_0                            (`country` == \"A\")  0.945985   \n",
       "2  cohort_1  ((`country` == \"B\")) or ((`country` == \"C\"))  0.941379   \n",
       "\n",
       "   precision    recall        f1  accuracy  threshold  num_pos     %_pos  \\\n",
       "0   0.927526  0.919864  0.923168  0.926000   0.500000     1822  0.607333   \n",
       "1   0.886854  0.902609  0.891498  0.894531   0.829787     1420  0.554688   \n",
       "2   0.845511  0.852320  0.838335  0.838636   0.151803      235  0.534091   \n",
       "\n",
       "   cht_size  \n",
       "0      3000  \n",
       "1      2560  \n",
       "2       440  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing = [dp.BasicImputer(verbose=False), dp.DataMinMaxScaler(verbose=False), dp.EncoderOHE(verbose=False)]\n",
    "\n",
    "dec_class = DecoupledClass(\n",
    "    cohort_col=[\"country\"],\n",
    "    transform_pipe=preprocessing,\n",
    "    estimator=get_model(),\n",
    "    minority_min_rate=0.2,\n",
    "    min_cohort_pct=0.15,\n",
    "    theta=False,\n",
    "    fairness_loss=\"dem_parity\",\n",
    "    lambda_coef=0.8,\n",
    "    max_joint_loss_time=2000\n",
    ")\n",
    "dec_class.fit(X_train, y_train)\n",
    "\n",
    "pred = dec_class.predict_proba(X_test)\n",
    "fetch_cohort_results(X_test, y_test, pred, cohort_def=dec_class, fixed_th=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using fairness optimization in addition to merging cohorts `(country==\"B\")` and `(country==\"C\")` shows an even better distribution of the labels. Although, one should pay attention to the trade-off between accuracy and label distribution when borrowing training data from other cohorts as the merging capability of this tool does."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raipub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "98cf402749abf383affb54f23cdde06b52ae2a6e4394659b91d1cafca4224ff4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
