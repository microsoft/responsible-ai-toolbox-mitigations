{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cohort Case Study 1 - Using RAI ErrorAnalysis\n",
    "\n",
    "We'll repeat the experiment demonstrated in [Case 1](./case_1.ipynb), but this time we'll be using the [Error Analysis Dashboard](https://erroranalysis.ai/), available in the [Responsible AI Toolbox](https://github.com/microsoft/responsible-ai-toolbox) project) to determine which cohorts of data this model performs worse on. To install this library, use the following command:\n",
    "\n",
    "```console\n",
    "> pip install raiwidgets\n",
    "```\n",
    "\n",
    "To see how to transfer cohorts between ``raimitigations`` and ``raiwidgets``, [check our tutorial on saving cohorts](./integration_raiwidgets.ipynb).\n",
    "\n",
    "In the following cells, we'll create the toy dataset once more, but this time we won't add any missing values into the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from raimitigations.utils import split_data\n",
    "import raimitigations.dataprocessing as dp\n",
    "from raimitigations.cohort import (\n",
    "    CohortDefinition,\n",
    "    CohortManager,\n",
    "    fetch_cohort_results\n",
    ")\n",
    "\n",
    "SEED = 51\n",
    "#SEED = None\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "def _create_country_df(samples: int, sectors: dict, country_name: str):\n",
    "    df = None\n",
    "    for key in sectors.keys():\n",
    "        size = int(samples * sectors[key][\"prob_occur\"])\n",
    "        invest = np.random.uniform(low=sectors[key][\"min\"], high=sectors[key][\"max\"], size=size)\n",
    "        min_invest = min(invest)\n",
    "        max_invest = max(invest)\n",
    "        range_invest = max_invest - min_invest\n",
    "        bankrupt_th = sectors[key][\"prob_success\"] * range_invest\n",
    "        inverted_behavior = sectors[key][\"inverted_behavior\"]\n",
    "        bankrupt = []\n",
    "        for i in range(invest.shape[0]):\n",
    "            inst_class = 1\n",
    "            if invest[i] > bankrupt_th:\n",
    "                inst_class = 0\n",
    "            if inverted_behavior:\n",
    "                inst_class = int(not inst_class)\n",
    "            bankrupt.append(inst_class)\n",
    "        noise_ind = np.random.choice(range(size), int(size*0.05), replace=False)\n",
    "        for ind in noise_ind:\n",
    "            bankrupt[ind] = int(not bankrupt[ind])\n",
    "        \n",
    "        country_col = [country_name for _ in range(size)]\n",
    "        sector_col = [key for _ in range(size)]\n",
    "        df_sector = pd.DataFrame({\n",
    "            \"investment\":invest,\n",
    "            \"sector\":sector_col,\n",
    "            \"country\":country_col,\n",
    "            \"bankrupt\":bankrupt\n",
    "        })\n",
    "        \n",
    "        if df is None:\n",
    "            df = df_sector\n",
    "        else:\n",
    "            df = pd.concat([df, df_sector], axis=0)\n",
    "    return df\n",
    "\n",
    "def create_df_multiple_distributions(samples: list):\n",
    "    sectors_c1 = {\n",
    "        \"s1\": {\"prob_occur\":0.5, \"prob_success\":0.99, \"inverted_behavior\":False, \"min\":2e6, \"max\":1e7},\n",
    "        \"s2\": {\"prob_occur\":0.1, \"prob_success\":0.2, \"inverted_behavior\":False, \"min\":1e7, \"max\":1.5e9},\n",
    "        \"s3\": {\"prob_occur\":0.1, \"prob_success\":0.9, \"inverted_behavior\":True, \"min\":1e9, \"max\":1e10},\n",
    "        \"s4\": {\"prob_occur\":0.3, \"prob_success\":0.7, \"inverted_behavior\":False, \"min\":4e10, \"max\":9e13},\n",
    "    }\n",
    "    sectors_c2 = {\n",
    "        \"s1\": {\"prob_occur\":0.1, \"prob_success\":0.6, \"inverted_behavior\":True, \"min\":1e3, \"max\":5e3},\n",
    "        \"s2\": {\"prob_occur\":0.3, \"prob_success\":0.9, \"inverted_behavior\":False, \"min\":1e5, \"max\":1.5e6},\n",
    "        \"s3\": {\"prob_occur\":0.5, \"prob_success\":0.3, \"inverted_behavior\":False, \"min\":5e4, \"max\":3e5},\n",
    "        \"s4\": {\"prob_occur\":0.1, \"prob_success\":0.8, \"inverted_behavior\":False, \"min\":1e6, \"max\":1e7},\n",
    "    }\n",
    "    sectors_c3 = {\n",
    "        \"s1\": {\"prob_occur\":0.3, \"prob_success\":0.9, \"inverted_behavior\":False, \"min\":3e2, \"max\":6e2},\n",
    "        \"s2\": {\"prob_occur\":0.6, \"prob_success\":0.7, \"inverted_behavior\":False, \"min\":5e3, \"max\":9e3},\n",
    "        \"s3\": {\"prob_occur\":0.07, \"prob_success\":0.6, \"inverted_behavior\":False, \"min\":4e3, \"max\":2e4},\n",
    "        \"s4\": {\"prob_occur\":0.03, \"prob_success\":0.1, \"inverted_behavior\":True, \"min\":6e5, \"max\":1.3e6},\n",
    "    }\n",
    "    countries = {\n",
    "        \"A\":{\"sectors\":sectors_c1, \"sample_rate\":0.85},\n",
    "        \"B\":{\"sectors\":sectors_c2, \"sample_rate\":0.05},\n",
    "        \"C\":{\"sectors\":sectors_c2, \"sample_rate\":0.1}\n",
    "    }\n",
    "    df = None\n",
    "    for key in countries.keys():\n",
    "        n_sample = int(samples * countries[key][\"sample_rate\"])\n",
    "        df_c = _create_country_df(n_sample, countries[key][\"sectors\"], key)\n",
    "        if df is None:\n",
    "            df = df_c\n",
    "        else:\n",
    "            df = pd.concat([df, df_c], axis=0)\n",
    "    \n",
    "    idx = pd.Index([i for i in range(df.shape[0])])\n",
    "    df = df.set_index(idx)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>investment</th>\n",
       "      <th>sector</th>\n",
       "      <th>country</th>\n",
       "      <th>bankrupt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.405851e+06</td>\n",
       "      <td>s1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.357697e+06</td>\n",
       "      <td>s1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.746429e+06</td>\n",
       "      <td>s1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.152158e+06</td>\n",
       "      <td>s1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.273704e+06</td>\n",
       "      <td>s1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>5.628480e+06</td>\n",
       "      <td>s4</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>4.907502e+06</td>\n",
       "      <td>s4</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9.941936e+06</td>\n",
       "      <td>s4</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>5.940903e+06</td>\n",
       "      <td>s4</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>8.602032e+06</td>\n",
       "      <td>s4</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        investment sector country  bankrupt\n",
       "0     7.405851e+06     s1       A         1\n",
       "1     2.357697e+06     s1       A         1\n",
       "2     4.746429e+06     s1       A         1\n",
       "3     7.152158e+06     s1       A         1\n",
       "4     4.273704e+06     s1       A         1\n",
       "...            ...    ...     ...       ...\n",
       "9995  5.628480e+06     s4       C         1\n",
       "9996  4.907502e+06     s4       C         1\n",
       "9997  9.941936e+06     s4       C         0\n",
       "9998  5.940903e+06     s4       C         1\n",
       "9999  8.602032e+06     s4       C         0\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_df_multiple_distributions(10000)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Pipeline for the entire dataset\n",
    "\n",
    "We'll now use our baseline approach, where we use a single pipeline to be trained using the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = \"bankrupt\"\n",
    "df_train, df_test = split_data(df, label=label_col, test_size=0.3, full_df=True)\n",
    "\n",
    "X_train = df_train.drop(columns=[label_col])\n",
    "y_train = df_train[label_col]\n",
    "X_test = df_test.drop(columns=[label_col])\n",
    "y_test = df_test[label_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    #model = LGBMClassifier(random_state=SEED)\n",
    "    model = LogisticRegression(random_state=SEED)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "            (\"imputer\", dp.BasicImputer(verbose=False)),\n",
    "            (\"scaler\", dp.DataMinMaxScaler(verbose=False)),\n",
    "            (\"encoder\", dp.EncoderOHE(verbose=False)),\n",
    "            (\"estimator\", get_model()),\n",
    "        ])\n",
    "model = pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the pipeline fitted, we can create the RAI Dashboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using categorical_feature in Dataset.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n"
     ]
    }
   ],
   "source": [
    "from raiwidgets import ResponsibleAIDashboard\n",
    "from responsibleai import RAIInsights\n",
    "from raiwidgets.cohort import Cohort, CohortFilter, CohortFilterMethods\n",
    "\n",
    "rai_insights = RAIInsights(model, df_train, df_test, label_col, 'classification',\n",
    "                           categorical_features=pipe['encoder'].get_encoded_columns())\n",
    "\n",
    "# Error Analysis\n",
    "rai_insights.error_analysis.add()\n",
    "\n",
    "rai_insights.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the following command to create a dashboard, which will be available in the localhost address printed below. We encourage users to interact with this dashboard and see all of the insights this dashboard offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponsibleAI started at http://localhost:5002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<raiwidgets.responsibleai_dashboard.ResponsibleAIDashboard at 0x7fc60ff64f70>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResponsibleAIDashboard(rai_insights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, our goal is to analyze the error distribution for the ``sector`` and ``country`` cohorts. In the dashboard, we'll click on the \"Heat map\" option and add the ``sector`` column as the \"Feature 1\", and the ``country`` column as \"Feature 2\".\n",
    "\n",
    "![screen1](./imgs/screen1.png)\n",
    "\n",
    "As we can see, the error is not evenly distributed among the cohorts. Some cohorts have high rates of errors, while other cohorts perform very well.\n",
    "\n",
    "## Different Pipelines for each cohort\n",
    "\n",
    "We'll now create a separate pipeline for each of the cohorts built according to the ``sector`` and ``country`` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using categorical_feature in Dataset.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n"
     ]
    }
   ],
   "source": [
    "cht_manager = CohortManager(\n",
    "    transform_pipe=[\n",
    "        dp.BasicImputer(verbose=False),\n",
    "        dp.DataMinMaxScaler(verbose=False),\n",
    "        dp.EncoderOHE(verbose=False),\n",
    "        get_model()\n",
    "    ],\n",
    "    cohort_col=[\"sector\", \"country\"]\n",
    ")\n",
    "cht_manager.fit(X_train, y_train)\n",
    "\n",
    "rai_insights = RAIInsights(cht_manager, df_train, df_test, label_col, 'classification',\n",
    "                           categorical_features=pipe['encoder'].get_encoded_columns())\n",
    "\n",
    "# Error Analysis\n",
    "rai_insights.error_analysis.add()\n",
    "\n",
    "rai_insights.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponsibleAI started at http://localhost:5003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<raiwidgets.responsibleai_dashboard.ResponsibleAIDashboard at 0x7fc60fb3a9d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResponsibleAIDashboard(rai_insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll repeat the same analysis done for the baseline pipeline.\n",
    "\n",
    "![screen2](./imgs/screen2.png)\n",
    "\n",
    "As we can see, the error is now evenly distributed among the cohorts.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('raipub')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98cf402749abf383affb54f23cdde06b52ae2a6e4394659b91d1cafca4224ff4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
