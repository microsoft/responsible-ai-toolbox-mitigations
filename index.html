<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Responsible AI Mitigations Library &mdash; Responsible AI Mitigations  documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="_static/graphviz.css" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Installation guide" href="install_guide.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="#" class="icon icon-home">
            Responsible AI Mitigations
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="install_guide.html">Installation guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="integration_to_libs.html">How this library works with the Responsible AI Toolbox</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="gallery.html">Gallery</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Modules</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dataprocessing/intro.html">DataProcessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="databalanceanalysis/intro.html">DataBalanceAnalysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="cohort/intro.html">Cohort</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils/utils.html">Utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">Responsible AI Mitigations</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Responsible AI Mitigations Library</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com//microsoft/responsible-ai-toolbox-mitigations/blob/main/docs/index.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="responsible-ai-mitigations-library">
<h1>Responsible AI Mitigations Library<a class="headerlink" href="#responsible-ai-mitigations-library" title="Permalink to this heading"></a></h1>
<p>The goal of responsible AI is to create trustworthy AI systems that benefit people while mitigating harms, which can occur when AI systems fail to
perform with fair, reliable, or safe outputs for various stakeholders. Teams tasked with developing AI systems must work to identify, diagnose, and
mitigate potential harms as much as possible. In this initial release, <strong>the Responsible AI Mitigations Library helps AI practitioners explore different
mitigation steps that may be most appropriate when the model underperforms for a given cohort.</strong> The library currently has three modules:</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference internal" href="dataprocessing/intro.html#dataproc"><span class="std std-ref">DataProcessing</span></a>: offers mitigation techniques for improving model performance for specific cohorts.</p></li>
<li><p><a class="reference internal" href="databalanceanalysis/intro.html#databalance"><span class="std std-ref">DataBalanceAnalysis</span></a>: provides metrics for diagnosing errors that originate from data imbalance either on class labels or feature values.</p></li>
<li><p><a class="reference internal" href="cohort/intro.html#cohort"><span class="std std-ref">Cohort</span></a>: provides classes for handling and managing cohorts, which allows the creation of custom pipelines for each cohort in an easy and
intuitive interface. The module also provides techniques for learning different decoupled estimators (models) for different cohorts and combining them in
a way that optimizes different definitions of group fairness.</p></li>
</ul>
</div></blockquote>
<section id="exploring-potential-mitigations">
<h2>Exploring potential mitigations<a class="headerlink" href="#exploring-potential-mitigations" title="Permalink to this heading"></a></h2>
<p>The Responsible AI Mitigations Library brings together in <strong>one interface and compatible end-to-end data-processing pipelines</strong> a series of well-known machine
learning techniques (based on popular implementations in scikit-learn, mlxtend, sdv, among others) that have been adapted to help AI practitioners <strong>target
problems after they have identified model errors</strong> using diagnostic tools such as those in the <a class="reference external" href="https://responsibleaitoolbox.ai/">Responsible AI Toolbox</a>. <a class="reference internal" href="integration_to_libs.html#integration-other-libs"><span class="std std-ref">See more</span></a>
about how this library works with the Responsible AI Toolbox.</p>
<figure class="align-default" id="id1">
<a class="reference internal image-reference" href="_images/diagnose_mitigate.png"><img alt="Diagnose and mitigate" src="_images/diagnose_mitigate.png" style="width: 651.9599999999999px; height: 402.47999999999996px;" /></a>
<figcaption>
<p><span class="caption-text">Figure 1 - The targeted approach to responsible AI mitigations focuses the mitigation process on previously identified and diagnosed failure modes.</span><a class="headerlink" href="#id1" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>After you’ve identified a model as underperforming for a specific cohort, the Responsible AI Mitigations Library can help inform your decisions for appropriate
mitigation. The library enables you to <strong>explore potential mitigations for targeted cohorts and sub-cohorts</strong> through:</p>
<blockquote>
<div><ul class="simple">
<li><p>Balancing and synthesizing data.</p></li>
<li><p>Selecting or creating features with different encodings.</p></li>
<li><p>Scaling numerical features.</p></li>
<li><p>Imputing missing values.</p></li>
</ul>
</div></blockquote>
<p><strong>Note:</strong> Although the Responsible AI Mitigations Library currently focuses on data problems, it will expand over time to include mitigations for model errors,
through customized loss functions, architectures, and new training algorithms.</p>
<div class="admonition-terminology-note admonition">
<p class="admonition-title">Terminology Note</p>
<p>The words “transformations” and “mitigations” are used interchangeably here, and both refer to an operation that changes the original dataset, with
the goal of mitigating some issue in the data. We also use the words “estimator” and “model” interchangeably, where both words refer to the object
that is trained over a dataset and then can be used to make predictions over new data.</p>
</div>
</section>
<section id="benefits-of-targeted-error-mitigations">
<span id="target-mitigation"></span><h2>Benefits of targeted error mitigations<a class="headerlink" href="#benefits-of-targeted-error-mitigations" title="Permalink to this heading"></a></h2>
<p>Traditional methods of improving model performance often take a blanket approach, aiming at maximizing a single-score performance number, such as overall accuracy.
Blanket approaches may involve increasing the size of training data or model architecture—approaches that are not only costly but also <strong>ineffective</strong> for improving the
model in areas of poorest performance.</p>
<figure class="align-default" id="id2">
<a class="reference internal image-reference" href="_images/balance_cohort.png"><img alt="Balancing over cohorts" src="_images/balance_cohort.png" style="width: 596.6px; height: 425.0px;" /></a>
<figcaption>
<p><span class="caption-text">Figure 2 - Example of how blanket approaches may not help in mitigating the underlying issue for a given cohort (in this case flipped class imbalance).</span><a class="headerlink" href="#id2" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>Imagine the following example. A model that predicts customer credit reliability is underperforming for a given cohort X. When analyzing class balance for the data, it
becomes clear that overall there are more examples in the data for which a loan has been assigned. However, for the cohort of interest X, this distribution looks very
different with more examples of loans being declined. The discrepancy also leads to a higher error for this cohort as the model learns to over-decline. Merely adding
more data to adjust overall class imbalance (Scenario 1 in the figure) will not address class imbalance for cohort X. In fact, it might make it worse by accentuating
class imbalance for this cohort and declining more loans. A more targeted approach (Scenario 2 in the figure) would focus the class balance mitigation only on cohort X
by sampling or synthesizing more data within that cohort where loans have been assigned. The Responsible AI Mitigations library can implement the second
scenario using two approaches:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Use the <a class="reference internal" href="dataprocessing/sampler/rebalance.html#rebalance"><span class="std std-ref">dataprocessing.Rebalance</span></a> together with the <a class="reference internal" href="cohort/cohort_manager.html#cohort-manager"><span class="std std-ref">cohort.CohortManager</span></a> in order to apply a over-sampling over only
a set of cohorts (check the <code class="docutils literal notranslate"><span class="pre">CohortManager</span></code>’s <a class="reference internal" href="cohort/cohort_manager.html#cohort-manager-ex"><span class="std std-ref">Examples</span></a> section to see how this can be achieved).</p></li>
<li><p>Synthesizing data only for a given cohort (see the <a class="reference internal" href="dataprocessing/sampler/synthesizer.html#syhtesizer"><span class="std std-ref">dataprocessing.Synthesizer</span></a> class for more information);</p></li>
</ol>
</div></blockquote>
<p>This way, the Responsible AI Mitigations Library offers a <strong>targeted approach that lets you save time and resources by</strong>:</p>
<blockquote>
<div><ul>
<li><p><strong>Improving your understanding of model failures</strong> by zeroing in on:</p>
<blockquote>
<div><ul class="simple">
<li><p>A set of features in the dataset, allowing changing format or encoding only the features that are problematic.</p></li>
<li><p>A sub-cohort only, not touching any other data.</p></li>
</ul>
</div></blockquote>
</li>
<li><p><strong>Simplifying the implementation and customization of mitigations</strong> for specific data problems by providing mitigations that are compatible with each other and can be
combined into a single pipeline. Most functionalities to this end can be found in the <a class="reference internal" href="cohort/cohort_manager.html#cohort-manager"><span class="std std-ref">cohort.CohortManager</span></a> class.</p></li>
<li><p><strong>Enabling custom training of cohort-specific models and post-training classifier mitigations</strong> that search and optimize different definitions of group fairness.
Most functionalities to this end can be found in the <a class="reference internal" href="cohort/cohort_manager.html#cohort-manager"><span class="std std-ref">cohort.CohortManager</span></a> and <a class="reference internal" href="cohort/decoupled_class.html#decoupled-class"><span class="std std-ref">cohort.DecoupledClass</span></a> class.</p></li>
</ul>
</div></blockquote>
<p>There are multiple ways of using the <a class="reference internal" href="cohort/cohort_manager.html#cohort-manager"><span class="std std-ref">cohort.CohortManager</span></a> class when building a pipeline, and these different scenarios are summarized in following figure.</p>
<figure class="align-default" id="id3">
<a class="reference internal image-reference" href="_images/scenarios.jpg"><img alt="Balancing over cohorts" src="_images/scenarios.jpg" style="width: 686.0px; height: 425.40000000000003px;" /></a>
<figcaption>
<p><span class="caption-text">Figure 3 - The CohortManager class can be used in different ways to target mitigations to different cohorts. The main differences between these scenarios consist on whether
the same or different type of data mitigation is applied to the cohort data, and whether a single or separate models will be trained for different cohorts. Depending on
these choices, CohortManager will take care of slicing the data accordingly, applying the specified data mitigation strategy, merging the data back, and retraining the model(s).</span><a class="headerlink" href="#id3" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>The <strong>Cohort Manager - Scenarios and Examples</strong> notebook, located in <code class="docutils literal notranslate"><span class="pre">notebooks/cohort/cohort_manager_scenarios.ipynb</span></code>, shows how each of these
scenarios can be implemented through simple code snippets.</p>
</section>
<section id="three-modules-for-targeted-error-mitigation">
<h2>Three modules for targeted error mitigation<a class="headerlink" href="#three-modules-for-targeted-error-mitigation" title="Permalink to this heading"></a></h2>
<p>The Responsible AI Mitigations Library consists of <strong>three modules that work in complement</strong> for targeting and mitigating data problems: DataProcessing and DataBalanceAnalysis.</p>
<section id="dataprocessing">
<h3><a class="reference internal" href="dataprocessing/intro.html#dataproc"><span class="std std-ref">DataProcessing</span></a><a class="headerlink" href="#dataprocessing" title="Permalink to this heading"></a></h3>
<p>A set of data-oriented mitigation steps for data balancing, scaling, missing value imputation, sampling, and encoding, using proven machine learning mitigation techniques
in a single interface and compatible environment. The goal of this module is to provide a unified interface for different mitigation methods scattered around multiple machine
learning libraries, such as scikit-learn, mlxtend, sdv, and others.</p>
<p><strong>Highlights include:</strong></p>
<blockquote>
<div><ul class="simple">
<li><p>A simple interface for mitigation steps that follows the <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> and <code class="docutils literal notranslate"><span class="pre">.transform()</span></code> convention.</p></li>
<li><p>transformer classes that can be combined together in end-to-end mitigation pipelines.</p></li>
<li><p>Function calls adapted for responsible AI by extending existing calls either with target features or cohorts.</p></li>
<li><p>Predetermined parameter values, eliminating the need to know or to configure all available parameters.</p></li>
<li><p>Unique solutions for tabular data.</p></li>
<li><p>Automation of various mitigation steps, with some transformer classes acting as a wrapper to others in the library.</p></li>
<li><p>Customization options, helpful for the more experienced AI practitioner.</p></li>
</ul>
</div></blockquote>
</section>
<section id="databalanceanalysis">
<h3><a class="reference internal" href="databalanceanalysis/intro.html#databalance"><span class="std std-ref">DataBalanceAnalysis</span></a><a class="headerlink" href="#databalanceanalysis" title="Permalink to this heading"></a></h3>
<p>A set of metrics for diagnosing and measuring data imbalance. This module is intended to be used as part of the error diagnosis process for failure modes that are due to class
or feature imbalance. After measuring with DataBalanceAnalysis, AI practitioners can then work to mitigate the failure through techniques available in the library’s DataProcessing
module.</p>
<div class="admonition-example admonition">
<p class="admonition-title">Example</p>
<p>A model trained for house-price prediction is discovered to be underperforming for houses that do not have an attached garage. The AI practitioner determines that this failure is
due to the underrepresentation of houses with no garage in the training data. The practitioner can use metrics in the DataBalanceAnalysis module to measure the feature imbalance
(“garage” vs. “no garage”), then work to mitigate the issue by using one of the sampling techniques available in the library’s DataProcessing module for augmenting data.</p>
</div>
</section>
<section id="cohort">
<h3><a class="reference internal" href="cohort/intro.html#cohort"><span class="std std-ref">Cohort</span></a><a class="headerlink" href="#cohort" title="Permalink to this heading"></a></h3>
<p>A sub-module that implements classes capable of handling and managing cohorts. This makes it easier for applying targeted mitigations over a specific cohort, or creating
custom data processing pipelines for each cohort. The <a class="reference internal" href="cohort/intro.html#cohort"><span class="std std-ref">Cohort</span></a> sub-module even allows creating different estimators for each cohort, without the user having to
explicitly manage multiple models. All is done internally in the class, with a unified and simple interface.</p>
<p><strong>Highlights include:</strong></p>
<blockquote>
<div><ul class="simple">
<li><p>Interface for breaking a dataset into multiple cohorts.</p></li>
<li><p>Two approaches for defining cohorts: based on the different values of a column, or based on custom filters.</p></li>
<li><p>Creation of custom pipelines for each cohort, allowing the creation of different estimators for each cohort.
Possibility to search and combine the custom estimators for each cohort such that jointly they optimize a group fairness definition of choice.</p></li>
<li><p>Mitigating cases with low representation data for minority cohorts through transfer learning.</p></li>
<li><p>Simple interface, which also implements the <code class="docutils literal notranslate"><span class="pre">.fit()</span></code>, <code class="docutils literal notranslate"><span class="pre">.transform()</span></code>, <code class="docutils literal notranslate"><span class="pre">.predict()</span></code>, <code class="docutils literal notranslate"><span class="pre">.predict_proba()</span></code>, and <code class="docutils literal notranslate"><span class="pre">.fit_resample()</span></code> methods
(some of these methods will only be available depending on the transformations/estimators in the custom pipelines defined for each cohort).</p></li>
</ul>
</div></blockquote>
<div class="admonition-example admonition">
<p class="admonition-title">Example</p>
<p>Consider a dataset of a classification problem that has a sensitive feature (<code class="docutils literal notranslate"><span class="pre">country</span></code> for example), and that each country-based cohort behaves differently, in the sense
that the classification logic may be different between cohorts, or that some other feature values may be considerably different ranges and interpretations across cohorts.
Depending on the estimator being used, these behavioral differences might not be captured, and in the end, the estimator
will simply try to understand the majority cohort, achieving good results for that cohort at the cost of achieving inferior results for the remaining ones. One way
to approach this problem is to apply targeted mitigations over each cohort separately. Some examples include using <a class="reference internal" href="dataprocessing/scaler/standard.html#standard-scaler"><span class="std std-ref">dataprocessing.DataStandardScaler</span></a>
over each cohort separately (e.g. for features like grades that have a different range in different countries), or even training a separate estimator for each cohort
(e.g. if some features are more or less relevant for some cohorts). This can all be achieved through the <a class="reference internal" href="cohort/cohort_manager.html#cohort-manager"><span class="std std-ref">cohort.CohortManager</span></a> class.
<a class="reference internal" href="cohort/case_studies.html#cohort-examples"><span class="std std-ref">Check-out these examples</span></a> for more details on how to use the <a class="reference internal" href="cohort/cohort_manager.html#cohort-manager"><span class="std std-ref">cohort.CohortManager</span></a> to create customized pipelines (including
an estimator for each cohort).</p>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="install_guide.html">Installation guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="integration_to_libs.html">How this library works with the Responsible AI Toolbox</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="gallery.html">Gallery</a></li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Modules</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dataprocessing/intro.html">DataProcessing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="dataprocessing/intro.html#structure">Structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="dataprocessing/intro.html#api">API</a></li>
<li class="toctree-l2"><a class="reference internal" href="dataprocessing/intro.html#examples">Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="dataprocessing/intro.html#scikit-learn-s-pipeline-support">scikit-learn’s Pipeline Support</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="databalanceanalysis/intro.html">DataBalanceAnalysis</a><ul>
<li class="toctree-l2"><a class="reference internal" href="databalanceanalysis/intro.html#api">API</a></li>
<li class="toctree-l2"><a class="reference internal" href="databalanceanalysis/intro.html#examples">Examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cohort/intro.html">Cohort</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cohort/intro.html#api">API</a></li>
<li class="toctree-l2"><a class="reference internal" href="cohort/intro.html#examples">Examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="utils/utils.html">Utils</a><ul>
<li class="toctree-l2"><a class="reference internal" href="utils/toy_data.html">Toy Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="utils/data_utils.html">Data Utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="utils/model_utils.html">Model Utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="utils/metric_utils.html">Metric Utils</a></li>
</ul>
</li>
</ul>
</div>
</section>
</section>
</section>
<section id="indices-and-tables">
<h1>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Permalink to this heading"></a></h1>
<ul class="simple">
<li><p><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></p></li>
<li><p><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></p></li>
</ul>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="install_guide.html" class="btn btn-neutral float-right" title="Installation guide" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Microsoft.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>